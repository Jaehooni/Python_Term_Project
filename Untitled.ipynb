{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import datetime\n",
    "import csv\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "def news_Finder(search_Sentence,start,end,file_Name):\n",
    "    \n",
    "    '''\n",
    "    (str,datetime.date,datetime.date(or datetime.datetime),str) ---> str\n",
    "    This function shows the number of news of particular date from start to end.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    #end에서 하루를 더 더한 날짜를 20XX.XX.XX 형태로 나타내어 반복문에서 원래 now 일자까지의 기사 개수가 나오도록 조정함.\n",
    "    end += datetime.timedelta(days=1)\n",
    "\n",
    "    #20XX.XX.XX로 형태를 조정하는 이유: naver에서 리퀘스트 할때 이 형태여야 하기 때문이다.\n",
    "    end_Date = end.strftime('%Y.%m.%d')\n",
    "\n",
    "    #기사 개수를 보길 원하는 시작 날짜을 20XX.XX.XX 형태로 나타냄.\n",
    "    start_Date = start.strftime('%Y.%m.%d')\n",
    "    \n",
    "\n",
    "    while start_Date != end_Date:\n",
    "        \n",
    "        #어떤 날짜인지 표시\n",
    "        print(start_Date)\n",
    "\n",
    "        #네이버에 리퀘스트를 요청할 날짜를 search_Date로 설정함.\n",
    "        search_Date = start_Date\n",
    "\n",
    "\n",
    "        #네이버에서 특정 일자의 특정 단어가 들어간 기사의 개수를 찾기 위한 URL 양식\n",
    "        address = 'https://search.naver.com/search.naver?where=news' + '&query={}&pd=3&ds={}&de={}'.format(search_Sentence,search_Date,search_Date)\n",
    "        \n",
    "\n",
    "        # HTTP GET Request\n",
    "        \n",
    "        req = requests.get(address)\n",
    "                \n",
    "       \n",
    "        #html 소스 가져오기\n",
    "        html = req.text\n",
    "        \n",
    "        # BeautifulSoup으로 html소스를 python객체로 변환하기\n",
    "        # 첫 인자는 html소스코드, 두 번째 인자는 어떤 parser를 이용할지 명시.\n",
    "\n",
    "        all_news_information = BeautifulSoup(html, 'html.parser')\n",
    "        \n",
    "        #Copy selecter에 의해 복사된 태그 사이에 들어가는 정보만 가져옴, 여기서는 뉴스 개수만 가져오기 위함임.\n",
    "        news_number_info = all_news_information.select('#main_pack > div.news.mynews.section._prs_nws > div.section_head > div.title_desc.all_my > span')\n",
    "\n",
    "        #엑셀 차트로 표현하기 위해서 csv 모듈 이용해서 파일 작성\n",
    "        \n",
    "        file = open('data/'+file_Name+'.csv','a', encoding='euc-kr',newline='')\n",
    "        csvWriter = csv.writer(file)\n",
    "\n",
    "        #뉴스 개수가 존재하지 않아 태그에 해당하는 정보가 존재하지 않을 때 0건이라는 내용 출력\n",
    "        if not news_number_info:\n",
    "            \n",
    "            csvWriter.writerow([search_Sentence,search_Date,'0건'])\n",
    "\n",
    "\n",
    "        #데이터들 중에서 온전히 뉴스 개수만 가져오기 위한 과정\n",
    "        else:\n",
    "\n",
    "            news_number_info = str(news_number_info[0])\n",
    "            change_to_news_number = (news_number_info.split(' / '))[1]\n",
    "            only_news_number = (change_to_news_number.split('<'))[0]\n",
    "\n",
    "            csvWriter.writerow([search_Sentence,search_Date,only_news_number])\n",
    "\n",
    "        \n",
    "        \n",
    "        # 한 과정이 끝날때마다 다음 날짜 뉴스로 넘어가기 위함\n",
    "        start = start + datetime.timedelta(days=1)\n",
    "        start_Date = start.strftime('%Y.%m.%d')\n",
    "    \n",
    "    file.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019.01.10\n",
      "2019.01.11\n",
      "2019.01.12\n",
      "2019.01.13\n",
      "2019.01.14\n",
      "2019.01.15\n",
      "2019.01.16\n",
      "2019.01.17\n",
      "2019.01.18\n",
      "2019.01.19\n",
      "2019.01.20\n",
      "2019.01.21\n",
      "2019.01.22\n",
      "2019.01.23\n",
      "2019.01.24\n",
      "2019.01.25\n",
      "2019.01.26\n",
      "2019.01.27\n",
      "2019.01.28\n",
      "2019.01.29\n",
      "2019.01.30\n",
      "2019.01.31\n",
      "2019.02.01\n",
      "2019.02.02\n",
      "2019.02.03\n",
      "2019.02.04\n",
      "2019.02.05\n",
      "2019.02.06\n",
      "2019.02.07\n",
      "2019.02.08\n",
      "2019.02.09\n",
      "2019.02.10\n",
      "2019.02.11\n",
      "2019.02.12\n",
      "2019.02.13\n",
      "2019.02.14\n",
      "2019.02.15\n",
      "2019.02.16\n",
      "2019.02.17\n",
      "2019.02.18\n",
      "2019.02.19\n",
      "2019.02.20\n",
      "2019.02.21\n",
      "2019.02.22\n",
      "2019.02.23\n",
      "2019.02.24\n",
      "2019.02.25\n",
      "2019.02.26\n",
      "2019.02.27\n",
      "2019.02.28\n",
      "2019.03.01\n",
      "2019.03.02\n",
      "2019.03.03\n",
      "2019.03.04\n",
      "2019.03.05\n",
      "2019.03.06\n",
      "2019.03.07\n",
      "2019.03.08\n",
      "2019.03.09\n",
      "2019.03.10\n",
      "2019.03.11\n",
      "2019.03.12\n",
      "2019.03.13\n",
      "2019.03.14\n",
      "2019.03.15\n",
      "2019.03.16\n",
      "2019.03.17\n",
      "2019.03.18\n",
      "2019.03.19\n",
      "2019.03.20\n",
      "2019.03.21\n",
      "2019.03.22\n",
      "2019.03.23\n",
      "2019.03.24\n",
      "2019.03.25\n",
      "2019.03.26\n",
      "2019.03.27\n",
      "2019.03.28\n",
      "2019.03.29\n",
      "2019.03.30\n",
      "2019.03.31\n",
      "2019.04.01\n",
      "2019.04.02\n",
      "2019.04.03\n",
      "2019.04.04\n",
      "2019.04.05\n",
      "2019.04.06\n",
      "2019.04.07\n",
      "2019.04.08\n",
      "2019.04.09\n",
      "2019.04.10\n",
      "2019.04.11\n",
      "2019.04.12\n",
      "2019.04.13\n",
      "2019.04.14\n",
      "2019.04.15\n",
      "2019.04.16\n",
      "2019.04.17\n",
      "2019.04.18\n",
      "2019.04.19\n",
      "2019.04.20\n",
      "2019.04.21\n",
      "2019.04.22\n",
      "2019.04.23\n",
      "2019.04.24\n",
      "2019.04.25\n",
      "2019.04.26\n",
      "2019.04.27\n",
      "2019.04.28\n",
      "2019.04.29\n",
      "2019.04.30\n",
      "2019.05.01\n",
      "2019.05.02\n",
      "2019.05.03\n",
      "2019.05.04\n",
      "2019.05.05\n",
      "2019.05.06\n",
      "2019.05.07\n",
      "2019.05.08\n",
      "2019.05.09\n",
      "2019.05.10\n",
      "2019.05.11\n",
      "2019.05.12\n",
      "2019.05.13\n",
      "2019.05.14\n",
      "2019.05.15\n",
      "2019.05.16\n",
      "2019.05.17\n",
      "2019.05.18\n",
      "2019.05.19\n",
      "2019.05.20\n",
      "2019.05.21\n",
      "2019.05.22\n",
      "2019.05.23\n",
      "2019.01.10\n",
      "2019.01.11\n",
      "2019.01.12\n",
      "2019.01.13\n",
      "2019.01.14\n",
      "2019.01.15\n",
      "2019.01.16\n",
      "2019.01.17\n",
      "2019.01.18\n",
      "2019.01.19\n",
      "2019.01.20\n",
      "2019.01.21\n",
      "2019.01.22\n",
      "2019.01.23\n",
      "2019.01.24\n",
      "2019.01.25\n",
      "2019.01.26\n",
      "2019.01.27\n",
      "2019.01.28\n",
      "2019.01.29\n",
      "2019.01.30\n",
      "2019.01.31\n",
      "2019.02.01\n",
      "2019.02.02\n",
      "2019.02.03\n",
      "2019.02.04\n",
      "2019.02.05\n",
      "2019.02.06\n",
      "2019.02.07\n",
      "2019.02.08\n",
      "2019.02.09\n",
      "2019.02.10\n",
      "2019.02.11\n",
      "2019.02.12\n",
      "2019.02.13\n",
      "2019.02.14\n",
      "2019.02.15\n",
      "2019.02.16\n",
      "2019.02.17\n",
      "2019.02.18\n",
      "2019.02.19\n",
      "2019.02.20\n",
      "2019.02.21\n",
      "2019.02.22\n",
      "2019.02.23\n",
      "2019.02.24\n",
      "2019.02.25\n",
      "2019.02.26\n",
      "2019.02.27\n",
      "2019.02.28\n",
      "2019.03.01\n",
      "2019.03.02\n",
      "2019.03.03\n",
      "2019.03.04\n",
      "2019.03.05\n",
      "2019.03.06\n",
      "2019.03.07\n",
      "2019.03.08\n",
      "2019.03.09\n",
      "2019.03.10\n",
      "2019.03.11\n",
      "2019.03.12\n",
      "2019.03.13\n",
      "2019.03.14\n",
      "2019.03.15\n",
      "2019.03.16\n",
      "2019.03.17\n",
      "2019.03.18\n",
      "2019.03.19\n",
      "2019.03.20\n",
      "2019.03.21\n",
      "2019.03.22\n",
      "2019.03.23\n",
      "2019.03.24\n",
      "2019.03.25\n",
      "2019.03.26\n",
      "2019.03.27\n",
      "2019.03.28\n",
      "2019.03.29\n",
      "2019.03.30\n",
      "2019.03.31\n",
      "2019.04.01\n",
      "2019.04.02\n",
      "2019.04.03\n",
      "2019.04.04\n",
      "2019.04.05\n",
      "2019.04.06\n",
      "2019.04.07\n",
      "2019.04.08\n",
      "2019.04.09\n",
      "2019.04.10\n",
      "2019.04.11\n",
      "2019.04.12\n",
      "2019.04.13\n",
      "2019.04.14\n",
      "2019.04.15\n",
      "2019.04.16\n",
      "2019.04.17\n",
      "2019.04.18\n",
      "2019.04.19\n",
      "2019.04.20\n",
      "2019.04.21\n",
      "2019.04.22\n",
      "2019.04.23\n",
      "2019.04.24\n",
      "2019.04.25\n",
      "2019.04.26\n",
      "2019.04.27\n",
      "2019.04.28\n",
      "2019.04.29\n",
      "2019.04.30\n",
      "2019.05.01\n",
      "2019.05.02\n",
      "2019.05.03\n",
      "2019.05.04\n",
      "2019.05.05\n",
      "2019.05.06\n",
      "2019.05.07\n",
      "2019.05.08\n",
      "2019.05.09\n",
      "2019.05.10\n",
      "2019.05.11\n",
      "2019.05.12\n",
      "2019.05.13\n",
      "2019.05.14\n",
      "2019.05.15\n",
      "2019.05.16\n",
      "2019.05.17\n",
      "2019.05.18\n",
      "2019.05.19\n",
      "2019.05.20\n",
      "2019.05.21\n",
      "2019.05.22\n",
      "2019.05.23\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = datetime.date(2019,1,10)\n",
    "end = datetime.datetime.now()\n",
    "search_Sentences = ['장자연','버닝썬']\n",
    "for search_Sentence in search_Sentences:\n",
    "    file_Name = search_Sentence\n",
    "    news_Finder(search_Sentence,start,end,file_Name)\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
