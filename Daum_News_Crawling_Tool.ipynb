{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Daum으로부터의 데이터 추출 코드, 네이버와 query 형식이 달라 조금 수정\n",
    "\n",
    "import requests\n",
    "import datetime\n",
    "import csv\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "\n",
    "def news_Finder(search_Sentence,start,end,file_Name):\n",
    "    \n",
    "    '''\n",
    "    (str,datetime.date,datetime.date(or datetime.datetime),str) ---> str\n",
    "    This function shows the number of news of particular date from start to end.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    #end에서 하루를 더 더해 반복문에서 원래 now 일자까지의 기사 개수가 나오도록 조정함.\n",
    "    end += datetime.timedelta(days=1)\n",
    "\n",
    "    #20XX00**로 형태를 조정하는 이유: daum에서 리퀘스트 할때 이 형태여야 하기 때문이다.\n",
    "    end_Date = end.strftime('%Y%m%d')\n",
    "\n",
    "    #기사 개수를 보길 원하는 시작 날짜을 20XX00** 형태로 나타냄.\n",
    "    start_Date = start.strftime('%Y%m%d')\n",
    "    \n",
    "    #엑셀 차트로 표현하기 위해서 csv 모듈 이용해서 파일 작성\n",
    "    file = open('Data/Daum/'+file_Name+'.csv','a', encoding='euc-kr',newline='')\n",
    "    csvWriter = csv.writer(file)\n",
    "    csvWriter.writerow(['검색어','검색 날짜','뉴스 개수'])\n",
    "    \n",
    "\n",
    "    while start_Date != end_Date:\n",
    "        \n",
    "        #어떤 날짜인지 표시\n",
    "        print(start.strftime('%Y.%m.%d'))\n",
    "\n",
    "        #다음에 리퀘스트를 요청할 날짜를 search_Date로 설정함.\n",
    "        search_Date = start_Date\n",
    "\n",
    "\n",
    "        #다음에서 특정 일자의 특정 단어가 들어간 기사의 개수를 찾기 위한 URL 양식\n",
    "        address = 'https://search.daum.net/search?w=news&sort=recency' + '&q={}&sd={}000000&ed={}235959&period=u'.format(search_Sentence,search_Date,search_Date)\n",
    "        print(address)\n",
    "\n",
    "        # HTTP GET Request\n",
    "        \n",
    "        req = requests.get(address)\n",
    "                \n",
    "       \n",
    "        #html 소스 가져오기\n",
    "        html = req.text\n",
    "        \n",
    "        # BeautifulSoup으로 html소스를 python객체로 변환하기\n",
    "        # 첫 인자는 html소스코드, 두 번째 인자는 어떤 parser를 이용할지 명시.\n",
    "\n",
    "        all_news_information = BeautifulSoup(html, 'html.parser')\n",
    "        \n",
    "        #Copy selecter에 의해 복사된 태그 사이에 들어가는 정보만 가져옴, 여기서는 뉴스 개수만 가져오기 위함임.\n",
    "        news_number_info = all_news_information.select('#resultCntArea')\n",
    "\n",
    "\n",
    "        #뉴스 개수가 존재하지 않아 태그에 해당하는 정보가 존재하지 않을 때 0건이라는 내용 출력\n",
    "        if not news_number_info:\n",
    "            \n",
    "            csvWriter.writerow([search_Sentence,start.strftime('%Y.%m.%d'),'0건'])\n",
    "\n",
    "\n",
    "        #데이터들 중에서 온전히 뉴스 개수만 가져오기 위한 과정\n",
    "        else:\n",
    "            only_news_number = ((((str(news_number_info[0])).split(' / '))[1]).split('<'))[0]\n",
    "            only_news_number = only_news_number.replace('약 ','').replace('건','').replace(',','')\n",
    "            \n",
    "            \n",
    "            csvWriter.writerow([search_Sentence,start.strftime('%Y.%m.%d'),only_news_number])\n",
    "\n",
    "\n",
    "        # 한 과정이 끝날때마다 다음 날짜 뉴스로 넘어가기 위함\n",
    "        start = start + datetime.timedelta(days=1)\n",
    "        start_Date = start.strftime('%Y%m%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Daum 사이트에서 데이터 추출\n",
    "\n",
    "import time\n",
    "start = datetime.date(2019,1,10)\n",
    "end = datetime.datetime.now()\n",
    "search_Sentences = ['장자연','버닝썬']\n",
    "for search_Sentence in search_Sentences:\n",
    "    file_Name = search_Sentence + '_Daum'\n",
    "    news_Finder(search_Sentence,start,end,file_Name)\n",
    "    time.sleep(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
