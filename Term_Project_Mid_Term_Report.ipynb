{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>(1) 주제 선정 이유</h3>\n",
    "<br>\n",
    "꽤 옛날부터 지금까지 정치 사건 직후, 연예건 사건이 터지는 일이 심심치 않게 있다.<br>\n",
    "<br>\n",
    "이에 따라 사람들이 정치계 사건을 덮기 위해서 고의로 연예계 사건을 터트리는 것 아니냐는 의혹이 계속되어 제기되고 있다.<br> \n",
    "<br>\n",
    "거기다가 이번에 다시금 재점화된 장자연 리스트도 최근 가장 크게 터진 연예계 사건인 버닝썬으로 덮이는 듯 하면서 <br>\n",
    "<br>\n",
    "이러한 의심이 국민의 의심이 극에 달했고, 그래서 나는 이번에 정말로 이러한 연예계 사건을 보도하는 것이 <br>\n",
    "<br>\n",
    "이전에 보도된 정치적 사건에 대한 관심을 줄이는 데 정말 효과적인 것인지 궁금하여 <br>\n",
    "<br>\n",
    "\"연예계 사건 보도가 정말 정치적 사건에 대한 관심 분산에 효과적인가? 에 대해서 조사해보려고 한다.\" <br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>(2) 가설 정의 </h3>\n",
    "<br>\n",
    "여러 언론사에서 의심하는 연관된 연예계와 정치계 사건을 찾아, 연예계 사건이 일어나기 전의 정치계 사건에<br>\n",
    "<br>\n",
    "대한 관심도를 SNS , 올라온 기사 수 등의 여러 항목의 개수로 측정해보고, 이후 연예계 사건이 터지고 나서 <br>\n",
    "<br>\n",
    "같은 측정 방법을 통해 다시 한번 정치계 사건에 대한 관심도를 측정하였을 시에, <br>\n",
    "<br>\n",
    "연예계 사건이 터지기 전보다 전체적인 개수가 줄어들었을 것이다. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> (3) 인터넷을 통한 데이터 획득 </h3>\n",
    "<br>\n",
    "먼저 Google 검색을 이용해 여러 언론사 및 개인이 연관되어 있다고 주장하는 연예계와 정치계 사건을 찾아보고 <br>\n",
    "<br>\n",
    "각 기사별로 하나의 그룹을 지어서 네이버 뉴스 등의 사이트를 이용해 매일 마다 사건 및 게시물 데이터들을 모을 것입니다. <br>\n",
    "<br>\n",
    "그러기 위해서 먼저<br>\n",
    "<br>\n",
    "<a href = \"https://www.naver.com/\" target = \"_blank\" >https://www.naver.com/ </a> <br>\n",
    "<br>\n",
    "에 들어가서 검색어를 입력해보며 검색어를 나타내는 리퀘스트와 특정 날짜를 지정할 수<br>\n",
    "<br>\n",
    "있는 리퀘스트가 무엇인지 파악하고서 그 다음 <br>\n",
    "<br>\n",
    "<a href = \"https://beomi.github.io/2017/01/20/HowToMakeWebCrawler/\" target = \"_blank\" >https://beomi.github.io/2017/01/20/HowToMakeWebCrawler/ </a> <br>\n",
    "<br>\n",
    "에서 나타난 것과 같이 python에서 지원하는 라이브러리인 requests와 beautifulsoup를 <br>\n",
    "<br>\n",
    "이용해 특정 데이터를 크롤링 할 수 있도록 합니다. <br>\n",
    "<br>\n",
    "이를 통해 특정 기간과 검색어를 파라메터로 가지는 함수를 생성하여 원하는 날짜 범위와 검색어를 설정하여 <br>\n",
    "<br>\n",
    "검색어에 해당하는 뉴스가 어느 날짜에 몇개가 나왔는지 볼 수 있도록 합니다. <br>\n",
    "<br>\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>(4) 분석을 위한 데이터 가공 </h3>\n",
    "<br>\n",
    "페이지 전체를 크롤링해서는 원하는 정보를 특정하기가 어려우므로 <br>\n",
    "<br>\n",
    "beautifulsoup 라이브러리의 Beautifulsoup 함수를 이용하여 전체를 긁어온다음 <br>\n",
    "<br>\n",
    "크롬의 select an element 기능을 이용해 특정 데이터에 해당하는 코드가 무엇인지 알아보고 <br>\n",
    "<br>\n",
    "Copy selecter를 활용, 그 코드에 해당하는 태그만을 가져옵니다. <br>\n",
    "<br>\n",
    "이리하여 가져온 '#main_pack > div.news.mynews.section._prs_nws > div.section_head > div.title_desc.all_my > span'와 같은 <br>\n",
    "<br>\n",
    "데이터에 해당하는 태그를 select 메소드의 파라메터로 집어넣어 특정 태그에 해당하는 데이터만을 가져올 수 있도록 합니다. <br>\n",
    "<br>\n",
    "그 후에 가져온 데이터에 불필요하게 붙어있는 태그를 python의 str 메소드 기능을 통해 <br>\n",
    "<br>\n",
    "필요한 알짜 데이터만 가져옵니다. <br>\n",
    "<br>\n",
    "\n",
    "\n",
    "\n",
    " \n",
    " \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>(5) 분석 결과 도출 </h3>\n",
    "<br>\n",
    "장자연 관련 뉴스.txt 첨부했음. <br>\n",
    "<br>\n",
    "별첨3에 첨부된 소스코드에서 <br>\n",
    "<br>\n",
    "search_Sentence = '장자연'<br>\n",
    "to = datetime.datetime.now()<br>\n",
    "from_ = datetime.date(2019,1,1)<br>\n",
    "<br>\n",
    "로 변수 값을 설정했을 때 나오는 결과임."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>(10) 별첨 3 </h3>\n",
    "<br>\n",
    "Python_Term_Project.ipynb 파일 첨부<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
